{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00d1728a-22b3-4a5c-8a3a-3d602e51ff86",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08a6e48-28ff-4bcf-b856-b8effb2ea15a",
   "metadata": {},
   "source": [
    "## Exam question 23-24 (1st session)\n",
    "\n",
    "Let us consider a regression task with $n=10$ inputs and one target.\n",
    "\n",
    "The regression dataset is in the variable \n",
    "<span style=\"font-family:Courier; \"> Q3_D </span> \n",
    "of the <span style=\"font-family:Courier; \"> fsel1.pkl </span> file.\n",
    "\n",
    "Note that the 11th column contains the target.\n",
    "\n",
    "\n",
    "Consider a **wrapper backward selection** strategy where the learner is a locally linear regression algorithm which returns the prediction of a linear model fitted to the K nearest neighbours (K=10 and Euclidean distance), and the assessment is based on leave-one-out.\n",
    "\n",
    "Return the index of the five most relevant features according to such feature selection strategy:\n",
    "\n",
    "Use the instructions\n",
    "```python\n",
    "import pickle\n",
    "with open(\"fsel1.pkl\", 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "Q3_D=data[\"Q3_D\"]\n",
    "```\n",
    "to load the <span style=\"font-family:Courier; \"> Q3_D </span> variable in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfb844f9-fa93-4e79-b3c4-ce77e09cd726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"fsel1.pkl\", 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "Q3_D=data[\"Q3_D\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62d4aef8-e2c4-49a0-815c-ec5a712d7d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 9, 10]\n",
      "[1, 3, 4, 5, 6, 7, 9, 10]\n",
      "[1, 3, 4, 5, 6, 7, 9]\n",
      "[1, 3, 4, 5, 7, 9]\n",
      "[1, 3, 5, 7, 9]\n",
      "[3, 5, 7, 9]\n",
      "[5, 7, 9]\n",
      "[5, 9]\n",
      "[9]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import solve\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def lsq(X, Y, q):\n",
    "    n = X.shape[1]\n",
    "    N = X.shape[0]\n",
    "    XX = np.column_stack((np.ones(N), X))\n",
    "    beta = solve(XX.T @ XX, XX.T @ Y)\n",
    "    yhat=np.concatenate((np.ones(1), q.flatten())) @ beta\n",
    "    return float(yhat[0])\n",
    "\n",
    "\n",
    "\n",
    "def LL(X, Y, q, k):\n",
    "    N = X.shape[0]\n",
    "    # Euclidean metric\n",
    "    d = np.sqrt(np.sum((X - np.ones((N, 1)) @ q.reshape(1, -1))**2, axis=1)) \n",
    "    index = np.argsort(d)[:k]\n",
    "    LLhat=lsq(X[index], Y[index], q)\n",
    "    return LLhat\n",
    "\n",
    "\n",
    "XY = Q3_D \n",
    "nn = XY.shape[1]\n",
    "X = XY[:, :nn-1]\n",
    "Y = XY[:, nn-1]\n",
    "\n",
    "n = X.shape[1]\n",
    "N = X.shape[0]\n",
    "nfeat = 10\n",
    "K = 10\n",
    "\n",
    "fsub = list(range(n))\n",
    "\n",
    "for ss in range(nfeat-1):\n",
    "    Eloo = np.full(n, np.inf)\n",
    "    for j in fsub:\n",
    "\n",
    "        Eloo[j] = 0\n",
    "\n",
    "        for i in range(N):\n",
    "            Xi = np.delete(X, i, axis=0)\n",
    "            Yi = np.delete(Y, i)        \n",
    "            remaining_features = [f for f in fsub if f != j]\n",
    "            Xi_subset = Xi[:, remaining_features]\n",
    "            X_i_subset = X[i:i+1, remaining_features]\n",
    "            Yhati = LL(Xi_subset, Yi.reshape(-1,1), X_i_subset, K)\n",
    "            Eloo[j] += (Y[i] - Yhati)**2\n",
    "\n",
    "        \n",
    "\n",
    "        Eloo[j] = Eloo[j]/N\n",
    "\n",
    "    \n",
    "    min_index = np.argmin(Eloo)\n",
    "    fsub.remove(min_index)\n",
    "    print([f+1 for f in fsub])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df18bb50-2677-4978-b5b0-1e19cb370ca0",
   "metadata": {},
   "source": [
    "## Exam question 22-23 (1st session)\n",
    "\n",
    "Let us consider a regression task with $n=10$ inputs and one target whose dataset is in the variable <span style=\"font-family:Courier; \"> D </span> \n",
    "of the  <span style=\"font-family:Courier; \"> fsel2.pkl </span> file.\n",
    "\n",
    "\n",
    "Note that the 11th column contains the target.\n",
    "\n",
    "Consider a wrapper forward selection strategy where the learner is a 5NN (KNN with $K=5$ and Euclidean distance), and the assessment is based on leave-one-out.\n",
    "\n",
    "Return the index of the five most relevant features according to this feature selection strategy\n",
    "\n",
    "Use the instructions\n",
    "```python\n",
    "import pickle\n",
    "with open(\"fsel2.pkl\", 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "D=data[\"D\"]\n",
    "```\n",
    "to load the <span style=\"font-family:Courier; \"> D </span> variable in Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7773306c-ddcd-4356-872d-727fe85fa080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"fsel2.pkl\", 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "D=data[\"D\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dfb0ae2-c6c3-4db1-ac62-47569c421cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestfs=[2, 3, 1, 6, 8] K=5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math # Import math for inf\n",
    "\n",
    "# Define the KNN function\n",
    "def KNN(X, Y, q, k):\n",
    "    # X: training features (numpy array)\n",
    "    # Y: training labels (numpy array)\n",
    "    # q: query point (numpy array, expected to be 2D, e.g., 1xM)\n",
    "    # k: number of neighbors\n",
    "    N = X.shape[0]\n",
    "\n",
    "    ones_matrix = np.ones((N, 1))\n",
    "    # Ensure q is treated as a row vector for matrix multiplication\n",
    "    q_matrix = q.reshape(1, -1) if q.ndim == 1 else q\n",
    "    d = np.sqrt(((X - (ones_matrix @ q_matrix))**2).sum(axis=1))\n",
    "\n",
    "    index = np.argsort(d)[:k]\n",
    "    return Y[index].mean()\n",
    "\n",
    "n = 10\n",
    "X = D[:, 0:n]\n",
    "Y = D[:, n]\n",
    "\n",
    "K = 5\n",
    "N = len(Y)\n",
    "n = X.shape[1]\n",
    "\n",
    "fsub = []\n",
    "nfeat = 5\n",
    "for ss in range(nfeat):\n",
    "\n",
    "   # Initialize Eloo (Leave-One-Out error) with infinity for each feature\n",
    "    # Eloo is a numpy array of size n (number of columns in X)\n",
    "    Eloo = np.full(n, np.inf)\n",
    "\n",
    "    for j in range(n):\n",
    "        if j in fsub:\n",
    "            continue # Skip this feature if it's already selected\n",
    "\n",
    "         Eloo[j] = 0\n",
    "\n",
    "        for i in range(N):\n",
    "\n",
    "            # Create the training data (Xi) and labels (Yi) by removing the i-th row/element\n",
    "            # np.delete removes the specified index along the specified axis\n",
    "            Xi = np.delete(X, i, axis=0)\n",
    "            Yi = np.delete(Y, i)\n",
    "\n",
    "            # Select the columns for the current subset of features (already selected fsub + candidate j)\n",
    "            # fsub contains 0-based indices, j is the current 0-based index\n",
    "            cols_subset = fsub + [j]\n",
    "\n",
    "            # Training data subset for KNN: select rows from Xi and the columns in cols_subset\n",
    "            Xi_subset = Xi[:, cols_subset]\n",
    "\n",
    "            # Test point for KNN: select the i-th row from the original X and the columns in cols_subset\n",
    "            # X[i, cols_subset] results in a 1D numpy array\n",
    "            # .reshape(1, -1) reshapes it into a 1xM matrix as expected by the KNN function's 'q' parameter\n",
    "            qi_subset = X[i, cols_subset].reshape(1, -1)\n",
    "\n",
    "            # Perform KNN prediction for the left-out data point\n",
    "            Yhati = KNN(Xi_subset, Yi, qi_subset, K)\n",
    "\n",
    "           # Accumulate the squared error for the current candidate feature j\n",
    "            # Y[i] is the actual label for the i-th data point (0-based index)\n",
    "            Eloo[j] = Eloo[j] + (Y[i] - Yhati)**2\n",
    "\n",
    "        # Calculate the mean squared error for the current candidate feature j\n",
    "        Eloo[j] = Eloo[j] / N\n",
    "\n",
    "    # Find the index (0-based) of the feature with the minimum mean squared error in Eloo\n",
    "    best_j = np.argmin(Eloo)\n",
    "    # Append the index of the best feature found in this iteration to the list of selected features\n",
    "    fsub.append(best_j)\n",
    "\n",
    "# Print the list of selected features (converting 0-based indices back to 1-based for output) and the value of K\n",
    "print(f\"bestfs={[x + 1 for x in fsub]} K={K}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2d9b9b-cf0f-4e45-b1f3-593d3e0c0efd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
