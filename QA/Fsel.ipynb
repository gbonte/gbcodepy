{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00d1728a-22b3-4a5c-8a3a-3d602e51ff86",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08a6e48-28ff-4bcf-b856-b8effb2ea15a",
   "metadata": {},
   "source": [
    "## Exam question 23-24 (1st session)\n",
    "\n",
    "Let us consider a regression task with $n=10$ inputs and one target.\n",
    "\n",
    "The regression dataset is in the variable \n",
    "<span style=\"font-family:Courier; \"> Q3_D </span> \n",
    "of the <span style=\"font-family:Courier; \"> fsel1.pkl </span> file.\n",
    "\n",
    "Note that the 11th column contains the target.\n",
    "\n",
    "\n",
    "Consider a **wrapper backward selection** strategy where the learner is a locally linear regression algorithm which returns the prediction of a linear model fitted to the K nearest neighbours (K=10 and Euclidean distance), and the assessment is based on leave-one-out.\n",
    "\n",
    "Return the index of the five most relevant features according to such feature selection strategy:\n",
    "\n",
    "Use the instructions\n",
    "```python\n",
    "import pickle\n",
    "with open(\"fsel1.pkl\", 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "Q3_D=data[\"Q3_D\"]\n",
    "```\n",
    "to load the <span style=\"font-family:Courier; \"> Q3_D </span> variable in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9557879-c1f4-4c3a-a431-f6a16499730f",
   "metadata": {},
   "source": [
    "## Dataset extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfb844f9-fa93-4e79-b3c4-ce77e09cd726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"fsel1.pkl\", 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "Q3_D=data[\"Q3_D\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c80127-246b-4e3d-8b3c-7c13a0c15bba",
   "metadata": {},
   "source": [
    "## Local linear modelling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62d4aef8-e2c4-49a0-815c-ec5a712d7d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import solve\n",
    "\n",
    "\n",
    "## least-squares prediction in the point q \n",
    "## Linear model is trained with the input matrix X and the output vector Y\n",
    "def lsq(X, Y, q):\n",
    "    n = X.shape[1]\n",
    "    N = X.shape[0]\n",
    "    XX = np.column_stack((np.ones(N), X))\n",
    "    beta = solve(XX.T @ XX, XX.T @ Y)\n",
    "    yhat=np.concatenate((np.ones(1), q.flatten())) @ beta\n",
    "    return float(yhat[0])\n",
    "\n",
    "\n",
    "## Selection of the k nearest neighbour and least squares fitting\n",
    "def LL(X, Y, q, k):\n",
    "    N = X.shape[0]\n",
    "    # Euclidean metric\n",
    "    d = np.sqrt(np.sum(np.square(X - q), axis=1))\n",
    "    index = np.argsort(d)[:k]\n",
    "    LLhat=lsq(X[index], Y[index], q)\n",
    "    return LLhat\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1617aac3-3d81-4eee-8675-a7e44d6efa95",
   "metadata": {},
   "source": [
    "## Wrapper backward selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18e71d4c-a479-4ce4-bc75-23d14d1b318b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 9, 10]\n",
      "[1, 3, 4, 5, 6, 7, 9, 10]\n",
      "[1, 3, 4, 5, 6, 7, 9]\n",
      "[1, 3, 4, 5, 7, 9]\n",
      "[1, 3, 5, 7, 9]\n",
      "[3, 5, 7, 9]\n",
      "[5, 7, 9]\n",
      "[5, 9]\n",
      "[9]\n"
     ]
    }
   ],
   "source": [
    "XY = Q3_D \n",
    "nn = XY.shape[1]\n",
    "X = XY[:, :nn-1]\n",
    "Y = XY[:, nn-1]\n",
    "\n",
    "n = X.shape[1]\n",
    "N = X.shape[0]\n",
    "nfeat = 10\n",
    "K = 10\n",
    "\n",
    "fsub = list(range(n))\n",
    "\n",
    "for ss in range(nfeat-1):\n",
    "    Eloo = np.full(n, np.inf)\n",
    "    for j in fsub:\n",
    "\n",
    "        Eloo[j] = 0\n",
    "\n",
    "        for i in range(N):\n",
    "            Xi = np.delete(X, i, axis=0)\n",
    "            Yi = np.delete(Y, i)        \n",
    "            remaining_features = [f for f in fsub if f != j]\n",
    "            Xi_subset = Xi[:, remaining_features]\n",
    "            X_i_subset = X[i:i+1, remaining_features]\n",
    "            Yhati = LL(Xi_subset, Yi.reshape(-1,1), X_i_subset, K)\n",
    "            Eloo[j] += (Y[i] - Yhati)**2\n",
    "\n",
    "        \n",
    "\n",
    "        Eloo[j] = Eloo[j]/N\n",
    "\n",
    "    \n",
    "    min_index = np.argmin(Eloo)\n",
    "    fsub.remove(min_index)\n",
    "    print([f+1 for f in fsub])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df18bb50-2677-4978-b5b0-1e19cb370ca0",
   "metadata": {},
   "source": [
    "## Exam question 22-23 (1st session)\n",
    "\n",
    "Let us consider a regression task with $n=10$ inputs and one target whose dataset is in the variable <span style=\"font-family:Courier; \"> D </span> \n",
    "of the  <span style=\"font-family:Courier; \"> fsel2.pkl </span> file.\n",
    "\n",
    "\n",
    "Note that the 11th column contains the target.\n",
    "\n",
    "Consider a **wrapper forward selection** strategy where the learner is a 5NN (KNN with $K=5$ and Euclidean distance), and the assessment is based on leave-one-out.\n",
    "\n",
    "Return the index of the five most relevant features according to this feature selection strategy\n",
    "\n",
    "Use the instructions\n",
    "```python\n",
    "import pickle\n",
    "with open(\"fsel2.pkl\", 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "D=data[\"D\"]\n",
    "```\n",
    "to load the <span style=\"font-family:Courier; \"> D </span> variable in Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7773306c-ddcd-4356-872d-727fe85fa080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"fsel2.pkl\", 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "D=data[\"D\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3dfb0ae2-c6c3-4db1-ac62-47569c421cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math # Import math for inf\n",
    "\n",
    "# Define the KNN function\n",
    "def KNN(X, Y, q, k):\n",
    "    # X: training features (numpy array)\n",
    "    # Y: training labels (numpy array)\n",
    "    # q: query point (numpy array,  1xn)\n",
    "    # k: number of neighbours\n",
    "    N = X.shape[0]\n",
    "\n",
    "    d = np.sqrt(np.sum(np.square(X - q), axis=1))\n",
    "\n",
    "    index = np.argsort(d)[:k]\n",
    "    return Y[index].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4dd6742-df57-40e0-8c4f-20fc1bf28406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestfs=[2, 3, 1, 6, 8] \n"
     ]
    }
   ],
   "source": [
    "n = 10 ## number of inputs\n",
    "X = D[:, 0:n]\n",
    "Y = D[:, n]\n",
    "\n",
    "K = 5\n",
    "N = len(Y)\n",
    "n = X.shape[1]\n",
    "\n",
    "fsub = []\n",
    "nfeat = 5\n",
    "for ss in range(nfeat):\n",
    "\n",
    "   # Initialize Eloo (Leave-One-Out error) with infinity for each feature\n",
    "    # Eloo is a numpy array of size n (number of columns in X)\n",
    "    Eloo = np.full(n, np.inf)\n",
    "\n",
    "    for j in range(n):\n",
    "        if j in fsub:\n",
    "            continue # Skip this feature if it's already selected\n",
    "\n",
    "        Eloo[j] = 0\n",
    "\n",
    "        for i in range(N):\n",
    "\n",
    "            # Create the training data (Xi) and labels (Yi) by removing the i-th row/element\n",
    "            # np.delete removes the specified index along the specified axis\n",
    "            Xi = np.delete(X, i, axis=0)\n",
    "            Yi = np.delete(Y, i)\n",
    "\n",
    "            # Select the columns for the current subset of features (already selected fsub + candidate j)\n",
    "            # fsub contains 0-based indices, j is the current 0-based index\n",
    "            cols_subset = fsub + [j]\n",
    "\n",
    "            # Training data subset for KNN: select rows from Xi and the columns in cols_subset\n",
    "            Xi_subset = Xi[:, cols_subset]\n",
    "\n",
    "            # Test point for KNN: select the i-th row from the original X and the columns in cols_subset\n",
    "            # X[i, cols_subset] results in a 1D numpy array\n",
    "            # .reshape(1, -1) reshapes it into a 1xM matrix as expected by the KNN function's 'q' parameter\n",
    "            qi_subset = X[i, cols_subset].reshape(1, -1)\n",
    "\n",
    "            # Perform KNN prediction for the left-out data point\n",
    "            Yhati = KNN(Xi_subset, Yi, qi_subset, K)\n",
    "\n",
    "           # Accumulate the squared error for the current candidate feature j\n",
    "            # Y[i] is the actual label for the i-th data point (0-based index)\n",
    "            Eloo[j] = Eloo[j] + (Y[i] - Yhati)**2\n",
    "\n",
    "        # Calculate the mean squared error for the current candidate feature j\n",
    "        Eloo[j] = Eloo[j] / N\n",
    "\n",
    "    # Find the index (0-based) of the feature with the minimum mean squared error in Eloo\n",
    "    best_j = np.argmin(Eloo)\n",
    "    # Append the index of the best feature found in this iteration to the list of selected features\n",
    "    fsub.append(best_j)\n",
    "\n",
    "# Print the list of selected features (converting 0-based indices back to 1-based for output) and the value of K\n",
    "print(f\"bestfs={[x + 1 for x in fsub]} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd549ef8-70fe-41ef-a9cd-5a5876cd7d60",
   "metadata": {},
   "source": [
    "## Exam question 22-23 (2nd session)\n",
    "\n",
    "Let us consider a classification task with $n=10$ binary inputs and one binary target whose dataset is in the variable <span style=\"font-family:Courier; \"> D </span> \n",
    "of the  <span style=\"font-family:Courier; \"> fsel3.pkl </span> file.\n",
    "\n",
    "Note that the 11th column contains the target.\n",
    "\n",
    "Consider a **wrapper backward selection** strategy in which the learner is a Naive Bayes, and the assessment is based on the leave-one-out misclassification.\n",
    "\n",
    "\n",
    "Use the instructions\n",
    "```python\n",
    "import pickle\n",
    "with open(\"fsel3.pkl\", 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "D=data[\"D\"]\n",
    "```\n",
    "to load the <span style=\"font-family:Courier; \"> D </span> variable in Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9162f745-996e-4d3b-b480-855eb3190359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"fsel3.pkl\", 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "D=data[\"D\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63353d2-8179-4c81-a953-a0bd001b63d9",
   "metadata": {},
   "source": [
    "## Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88bdab89-eec0-4121-8626-ffea67900b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def NB(X, Y, q):\n",
    "    n = X.shape[1]\n",
    "    N = len(Y)\n",
    "    P0 = len(np.where(Y == 0)[0]) / N\n",
    "    P1 = 1 - P0\n",
    "    \n",
    "    for i in range(n):\n",
    "        I = np.where(X[:, i] == q[0, i])[0]\n",
    "        I0 = np.where(Y[I] == 0)[0]\n",
    "        I1 = np.where(Y[I] == 1)[0]\n",
    "        P0 = P0 * len(I0) / len(I)\n",
    "        P1 = P1 * len(I1) / len(I)\n",
    "    \n",
    "    return 0 if P0 > P1 else 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06019f36-71c0-4e97-a391-f32243022354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  5 10]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "N = D.shape[0]  \n",
    "n = D.shape[1] - 1\n",
    "    \n",
    "X = D[:, :n]\n",
    "Y = D[:, n]\n",
    "    \n",
    "    \n",
    "Fset = np.arange(n) ## initial feature set\n",
    "\n",
    "for r in range(n-5):\n",
    "    Miscl = np.full(n, np.inf)\n",
    "\n",
    "    for j in range(n):\n",
    "        if j in Fset:\n",
    "            Ehat = 0\n",
    "            for i in range(N):\n",
    "                remaining_features = np.setdiff1d(Fset, j)\n",
    "                X_subset = X[np.arange(N) != i][:, remaining_features]\n",
    "                Y_subset = Y[np.arange(N) != i]\n",
    "                q = X[i:i+1, remaining_features]\n",
    "                Yhat = NB(X_subset, Y_subset, q)\n",
    "                Ehat += float(Yhat != Y[i])\n",
    "\n",
    "            Miscl[j] = Ehat/N\n",
    "\n",
    "    # Remove the feature that minimizes misclassification error\n",
    "    Fset = np.setdiff1d(Fset, np.argmin(Miscl))\n",
    "\n",
    "print(Fset+1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bff81a9-3985-453e-81cd-4ce324dec2d4",
   "metadata": {},
   "source": [
    "## LIN.QA.1\n",
    "\n",
    "Let us consider a regression task with $n=10$ inputs $ {\\mathbf x}_1, \\dots {\\mathbf x}_{10} $ and 1 output $ {\\mathbf y} $.\n",
    "\n",
    "Let the training set be in the variable <span style=\"font-family:Courier; \">D</span> in the pickle file <span style=\"font-family:Courier; \">data1.pkl</span>, where the first 10 columns contain the inputs and the last column contains the output.\n",
    "\n",
    "Suppose we want to perform an **embedded feature selection** by ridge regression where the set of values of the shrinkage parameter $ \\lambda $ are contained in the Python variable <span style=\"font-family:Courier; \"> lam</span>.\n",
    "\n",
    "By using Python\n",
    "* compute the optimal $ \\lambda $ shrinkage parameter for a ridge-regression approach by using a leave-one-out assessment strategy \n",
    "* for the optimal $ \\lambda $  computed above,  return the three most relevant features \n",
    "\n",
    "\n",
    "Note that you should use only basic Python functions.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f71b79e-e50c-4cd4-94d0-6c50899c27e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 11)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"data1.pkl\", 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "D=data[\"D\"].to_numpy()\n",
    "lam=data[\"lam\"].to_numpy()\n",
    "\n",
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c263d74f-bd88-4f72-8c7a-aef1ea17c49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestlambda=[0.2] fs=[2, 3, 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n = 10\n",
    "\n",
    "X = D[:, :n]\n",
    "Y = D[:, n]\n",
    "N = len(Y)\n",
    "\n",
    "XX = np.c_[np.ones(N), X]\n",
    "\n",
    "p = len(lam)\n",
    "\n",
    "Eloo = np.zeros(p)\n",
    "\n",
    "for j in range(p):\n",
    "    for i in range(N):\n",
    "        ## leave-one-out\n",
    "        Xi = XX[np.arange(N) != i, :]\n",
    "        Yi = Y[np.arange(N) != i]\n",
    "        betai = np.linalg.solve(Xi.T @ Xi + lam[j] * np.eye(n + 1), Xi.T @ Yi)\n",
    "        Yhati = XX[i, :] @ betai\n",
    "        Eloo[j] += (Y[i] - Yhati)**2\n",
    "    Eloo[j] = Eloo[j] / N\n",
    "\n",
    "bestlambda = lam[np.argmin(Eloo)]\n",
    "\n",
    "## computation of the beta coefficients for the optimal lambda\n",
    "beta = np.linalg.solve(XX.T @ XX + bestlambda * np.eye(n + 1), XX.T @ Y)\n",
    "\n",
    "\n",
    "## retrieval of the three most relevant features\n",
    "feature_coeffs_abs = np.abs(beta[1:n+1])\n",
    "top_3_indices_0based = np.argsort(-feature_coeffs_abs)[0:3]\n",
    "top_3_feature_indices_1based = top_3_indices_0based + 1\n",
    "\n",
    "print(f\"bestlambda={bestlambda} fs={list(top_3_feature_indices_1based)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279a8e86-20e8-4af0-a2cc-0cb704537a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623146c3-b628-4dc3-ad1e-489ecac78997",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
