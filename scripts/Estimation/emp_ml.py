import numpy as npfrom scipy.stats import normimport mathfrom scipy.optimize import minimize_scalar, minimize## "Statistical foundations of machine learning" software## Python package gbcodepy ## Author: G. Bontempi# Script: shows the use of maximum likelihood for parameter estimationnp.random.seed(0)def eml(m, D, var):   ## empirical likelihood function (1 argument)        N = len(D)    LLik = 0    for i in range(N):        LLik = LLik +np.log( norm.pdf(D[i], loc=m, scale=math.sqrt(var)))    return -(LLik)def eml2(m, D):   ## empirical log-likelihood function (2 arguments)    N = len(D)    LLik = 0    for i in range(N):        LLik = LLik +np.log( norm.pdf(D[i], loc=m[0], scale=math.sqrt(max(0.1, m[1]))))    return -(LLik)N = 20DN = np.random.randn(N) # data generationxmin = minimize_scalar(eml, bounds=(-10,10), args=(DN,1), method='bounded')# maximization of log likelihood function (1 argument)print("Mean ML estimation=", xmin.x, "\n")xmin2 = minimize(lambda m: eml2(m, DN), x0=np.array([-5,5]))# maximization of log likelihood function (2 arguments: mean and variance)print("Mean and variance ML estimation=", xmin2.x, "\n")print("Sample mean=", np.mean(DN)) ## sample averageprint("Sample variance=", np.var(DN)) ## sample mean with N at the denominator